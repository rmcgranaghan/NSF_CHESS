{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import bezpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "import datetime\n",
    "isotfmt = '%Y-%m-%dT%H:%M:%S.%f'\n",
    "def MJD2UT(mjd):\n",
    "    \"\"\" If given single value, will return single datetime.datetime\n",
    "    If given list, will return list of datetime.datetimes\n",
    "    \"\"\"\n",
    "    UT = Time(mjd, format='mjd').isot\n",
    "    if type(UT) == str:\n",
    "        return datetime.datetime.strptime(UT,isotfmt)\n",
    "    else:\n",
    "        return [datetime.datetime.strptime(UT[n],isotfmt) for n in range(len(UT))]\n",
    "\n",
    "\n",
    "def read_mage(fname):\n",
    "    \"\"\"Read the given MAGE h5 file\"\"\"\n",
    "    # The file of magnetic field data\n",
    "    # f = h5py.File(\"mageDB_SM.h5\", \"r\")\n",
    "    # f = h5py.File(\"booDB.deltab.h5\", \"r\")\n",
    "    f = h5py.File(fname, \"r\")\n",
    "    \n",
    "    ntimes = len([x for x in f.keys() if \"Step\" in x])\n",
    "    # Create the names manually to avoid sorting on non-zero padded strings\n",
    "    steps = [f\"Step#{i}\" for i in range(ntimes)]\n",
    "\n",
    "    # Calculate datetimes from the attributes\n",
    "    times = [MJD2UT(f[step].attrs[\"MJD\"]) for step in steps]\n",
    "\n",
    "    # Set up the arrays\n",
    "    lons = np.rad2deg(f[\"Phicc\"][0, ...]).ravel()\n",
    "    lons[lons > 180] -= 360\n",
    "    lats = 90 - np.rad2deg(f[\"Thetacc\"][0, ...]).ravel()\n",
    "    nsites = len(lons)\n",
    "    \n",
    "    dB = np.empty((ntimes, nsites, 2))\n",
    "    for i, step in enumerate(steps):\n",
    "        dB[i, :, 0] = -f[step][\"dBt\"][0, ...].ravel()  # Theta [colatitude] (X)\n",
    "        dB[i, :, 1] = f[step][\"dBp\"][0, ...].ravel()  # Phi (Y)\n",
    "\n",
    "    ds = xr.Dataset(coords={\"longitude\": (\"site\", lons),\n",
    "                          \"latitude\": (\"site\", lats),\n",
    "                          \"component\": [\"X\", \"Y\"],\n",
    "                          \"time\": times},\n",
    "                  data_vars={\"B\": ((\"time\", \"site\", \"component\"), dB)})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_swmf(dirname):\n",
    "    \"\"\"Read the SWMF output contained in the given directory\"\"\"\n",
    "    fnames = sorted(glob.glob(f\"{dirname}/*.out\"))\n",
    "    ntimes = len(fnames)\n",
    "    \n",
    "    # Read in the first file to get the shapes\n",
    "    test = pd.read_csv(fnames[0], delim_whitespace=True, header=3, usecols=[0, 1])\n",
    "    \n",
    "    npoints_swmf = len(test)\n",
    "    lons = test[\"Lon\"].to_numpy()\n",
    "    lons[lons > 180] -= 360\n",
    "    lats = test[\"Lat\"].to_numpy()\n",
    "    dB = np.empty((ntimes, npoints_swmf, 2))\n",
    "    times = []\n",
    "\n",
    "    # Now iterate over all the files\n",
    "    for i, fname in enumerate(fnames):\n",
    "        # Parse the filename for the date/time information\n",
    "        time = datetime.datetime.strptime(fname[-19:-6], \"%Y%m%d-%H%M\")\n",
    "        times.append(time)\n",
    "        df = pd.read_csv(fname, delim_whitespace=True, header=3, usecols=[2, 3])\n",
    "        dB[i, :, 0] = df[\"dBn\"].to_numpy()\n",
    "        dB[i, :, 1] = df[\"dBe\"].to_numpy()\n",
    "        \n",
    "    ds = xr.Dataset(coords={\"longitude\": (\"site\", lons),\n",
    "                          \"latitude\": (\"site\", lats),\n",
    "                          \"component\": [\"X\", \"Y\"],\n",
    "                          \"time\": times},\n",
    "                  data_vars={\"B\": ((\"time\", \"site\", \"component\"), dB)})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Impedance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_anna_file(fname):\n",
    "    model_sites = {}\n",
    "\n",
    "    with open(fname, 'r') as f:\n",
    "        # 10 lines of header... Can this change?\n",
    "        # YES! 0.25 degree files have 13\n",
    "        for i in range(13):\n",
    "            f.readline()\n",
    "\n",
    "        for line in f:\n",
    "            elements = line.split()\n",
    "            period = float(elements[0])\n",
    "            name = elements[1]\n",
    "            lat = float(elements[2])\n",
    "            lon = float(elements[3])\n",
    "            component = elements[7]\n",
    "            val = float(elements[8]) + float(elements[9])*1j\n",
    "\n",
    "            if name not in model_sites:\n",
    "                site = bezpy.mt.Site3d(name)\n",
    "                model_sites[name] = site\n",
    "                site.latitude = lat\n",
    "                site.longitude = lon\n",
    "                # 45 periods in the dataset\n",
    "                site.periods = np.zeros(45)\n",
    "                site.Z = np.zeros((4, 45), dtype=complex)\n",
    "                old_period = 0.\n",
    "                period_counter = -1\n",
    "\n",
    "            if period != old_period:\n",
    "                period_counter += 1\n",
    "                old_period = period\n",
    "                site.periods[period_counter] = period\n",
    "\n",
    "            if component == 'ZXX':\n",
    "                loc = 0\n",
    "            elif component == 'ZXY':\n",
    "                loc = 1\n",
    "            elif component == 'ZYX':\n",
    "                loc = 2\n",
    "            elif component == 'ZYY':\n",
    "                loc = 3\n",
    "\n",
    "            site.Z[loc,period_counter] = val\n",
    "            \n",
    "    # Calculate resistivity before returning\n",
    "    [site.calc_resisitivity() for site in model_sites.values()]\n",
    "        \n",
    "    return model_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(impedance_sites, ds):\n",
    "    \"\"\"Create a mapping from impedance sites to magnetic field location\"\"\"\n",
    "    impedance_xys = np.array([(x.longitude, x.latitude) for x in impedance_sites])\n",
    "    # Store a mapping from k -> (i, j)\n",
    "    # impedance site location (k) -> magnetic field location (i, j)\n",
    "    # NOTE: The values are shifted by 1/8 degree due to cell centered vs edges\n",
    "    #       between the two datasets\n",
    "    mapping_dict = {}\n",
    "    for k in range(len(impedance_xys)):\n",
    "        arr_i = np.argmin(abs(impedance_xys[k, 0] - ds[\"longitude\"].to_numpy()) + abs(impedance_xys[k, 1] - ds[\"latitude\"].to_numpy()))\n",
    "        mapping_dict[k] = arr_i\n",
    "    return mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_e(mapping_dict, b_ds):\n",
    "    \"\"\"Calculate the electric field at the impedance locations.\"\"\"\n",
    "    b_model = b_ds[\"B\"].to_numpy()\n",
    "    # Create an empty Electric field dataset that we can index into\n",
    "    ntimes = b_model.shape[0]\n",
    "    # We actually want B/E to be on the impedance site grid, not the original\n",
    "    # model grid\n",
    "    b = np.zeros((ntimes, nsites, 2))\n",
    "    e = np.zeros_like(b)\n",
    "\n",
    "    lons = []\n",
    "    lats = []\n",
    "    for site_num, site in enumerate(model_sites_sorted):\n",
    "        lons.append(site.longitude)\n",
    "        lats.append(site.latitude)\n",
    "        # Pull out the magnetic field components for this site\n",
    "        i = mapping_dict[site_num]\n",
    "        b[:, site_num, 0], b[:, site_num, 1] = b_model[:, i, 0], b_model[:, i, 1]\n",
    "        e[:, site_num, 0], e[:, site_num, 1] = site.convolve_fft(b[:, site_num, 0], b[:, site_num, 1], dt=60)\n",
    "        \n",
    "    # Create a new dataset\n",
    "    ds = xr.Dataset(coords={\"longitude\": (\"site\", lons),\n",
    "                          \"latitude\": (\"site\", lats),\n",
    "                          \"component\": [\"X\", \"Y\"],\n",
    "                          \"time\": b_ds[\"time\"]},  # Same as model times\n",
    "                  data_vars={\"B\": ((\"time\", \"site\", \"component\"), b),\n",
    "                             \"E\": ((\"time\", \"site\", \"component\"), e)})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17765 model points\n"
     ]
    }
   ],
   "source": [
    "fname = 'USA_impedance_gridded_45per_0.25x0.25-SP2.dat'\n",
    "model_sites_all = read_anna_file(fname)\n",
    "\n",
    "model_sites = {}\n",
    "for name in model_sites_all:\n",
    "    site = model_sites_all[name]\n",
    "    model_sites[name] = site\n",
    "\n",
    "del model_sites_all\n",
    "model_sites_sorted = sorted(model_sites.values(), key=lambda x: (x.longitude, x.latitude))\n",
    "nsites = len(model_sites_sorted)\n",
    "print(f\"There are {nsites} model points\")\n",
    "site_xys = np.array([(x.longitude, x.latitude) for x in model_sites_sorted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmission lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_transmission_lines():\n",
    "# pickle delaunay calculations which is often a speed bottleneck\n",
    "    try:\n",
    "        return pd.read_pickle(\"transmission_line_objects.pkl\")\n",
    "    except FileNotFoundError:\n",
    "        # Only recalculate if the weights haven't been filled before\n",
    "        print(\"No transmission line pickle files found, loading the data\"\n",
    "              \"and calculating values manually which can be slow\")\n",
    "        \n",
    "    df = gpd.read_file(\"Electric_Power_Transmission_Lines.shp\")\n",
    "    # Change all MultiLineString into LineString objects by grabbing the first line\n",
    "    # Will miss a few coordinates, but should be OK as an approximation\n",
    "    df.loc[df[\"geometry\"].apply(lambda x: x.geometryType()) == \"MultiLineString\",\"geometry\"] = \\\n",
    "        df.loc[df[\"geometry\"].apply(lambda x: x.geometryType()) == \"MultiLineString\",\"geometry\"].apply(lambda x: x[0])\n",
    "\n",
    "    # Get rid of erroneous 1MV and low power line voltages\n",
    "    df = df[(df[\"VOLTAGE\"] < 1000) & (df[\"VOLTAGE\"] >= 200)]\n",
    "\n",
    "    df[\"obj\"] = df.apply(bezpy.tl.TransmissionLine, axis=1)\n",
    "    df[\"length\"] = df.obj.apply(lambda x: x.length)\n",
    "\n",
    "    print(\"Starting delaunay calculations which can take ~20 minutes\")\n",
    "    t1 = time.time()\n",
    "    df.obj.apply(lambda x: x.set_delaunay_weights(site_xys, use_gnomic=False))\n",
    "    print(f\"Done filling interpolation weights: {time.time() - t1} s\".format())\n",
    "    # Create the pickle object so we can load faster next time\n",
    "    df.to_pickle(\"transmission_line_objects.pkl\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_voltages(df_lines, ds_E):\n",
    "    \"\"\"Calculate the voltages along the lines for the given electric field time-series\"\"\"\n",
    "    ntimes = len(ds_E[\"time\"])\n",
    "    n_trans_lines = len(df)\n",
    "    arr_delaunay = np.zeros(shape=(ntimes, n_trans_lines))\n",
    "    e_fields = ds_E[\"E\"].to_numpy()\n",
    "    # Iterate over all transmission lines to do the integration\n",
    "    for i, t_line in enumerate(df_lines.obj):\n",
    "        arr_delaunay[:, i] = t_line.calc_voltages(e_fields, how='delaunay')\n",
    "    \n",
    "    # We need to add a new coordinate, the \"line\" which corresponds to the index\n",
    "    # in the line dataframe\n",
    "    ds_E = ds_E.assign_coords({\"line\": np.arange(n_trans_lines)})\n",
    "    # gic_proxy = V / R = V / (resistivity * line_length)\n",
    "    rho_line = 0.1  # Ohms/km (Grigsby 2007)\n",
    "    ds_E = ds_E.assign({\"V\": ((\"time\", \"line\"), arr_delaunay),\n",
    "                        \"I\": ((\"time\", \"line\"), arr_delaunay / ((rho_line * df_lines[\"length\"].to_numpy())[np.newaxis, :]))})\n",
    "    return ds_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_transmission_lines()\n",
    "\n",
    "try:\n",
    "    mage_ds = xr.load_dataset(\"mage_data.nc\")\n",
    "except FileNotFoundError:\n",
    "    # Create the data and save it\n",
    "    mage_ds = read_mage(\"finBoo.deltab.h5\")\n",
    "    mage_mapping = create_mapping(model_sites_sorted, mage_ds)\n",
    "    mage_ds = calc_e(mage_mapping, mage_ds)\n",
    "    mage_ds = calc_voltages(df, mage_ds)\n",
    "    mage_ds.to_netcdf(\"mage_data.nc\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read in all the files and transform to the impedance grid\n",
    "# Try loading first, and if it hasn't been computed then calculate the B/E-fields\n",
    "# We need the dataframe of transmission lines for plotting\n",
    "df = get_transmission_lines()\n",
    "\n",
    "try:\n",
    "    mage_ds = xr.load_dataset(\"mage_data.nc\")\n",
    "except FileNotFoundError:\n",
    "    # Create the data and save it\n",
    "    mage_ds = read_mage(\"halloweenQ.deltab.h5\")\n",
    "    mage_mapping = create_mapping(model_sites_sorted, mage_ds)\n",
    "    mage_ds = calc_e(mage_mapping, mage_ds)\n",
    "    mage_ds = calc_voltages(df, mage_ds)\n",
    "    mage_ds.to_netcdf(\"mage_data.nc\")\n",
    "\n",
    "try:\n",
    "    swpc_ds = xr.load_dataset(\"swpc_data.nc\")\n",
    "except FileNotFoundError:\n",
    "    swpc_ds = read_swmf(\"swpc_geospace_v2_usa_2x2_grid\")\n",
    "    swpc_mapping = create_mapping(model_sites_sorted, swpc_ds)\n",
    "    swpc_ds = calc_e(swpc_mapping, swpc_ds)\n",
    "    swpc_ds = calc_voltages(df, swpc_ds)\n",
    "    swpc_ds.to_netcdf(\"swpc_data.nc\")\n",
    "\n",
    "try:\n",
    "    umich_ds = xr.load_dataset(\"umich_data.nc\")\n",
    "except FileNotFoundError:\n",
    "    umich_ds = read_swmf(\"Event01\")\n",
    "    umich_mapping = create_mapping(model_sites_sorted, umich_ds)\n",
    "    umich_ds = calc_e(umich_mapping, umich_ds)\n",
    "    umich_ds = calc_voltages(df, umich_ds)\n",
    "    umich_ds.to_netcdf(\"umich_data.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a regular grid of (x, y) pairs\n",
    "gridx, gridy = np.meshgrid(sorted(np.unique(site_xys[:, 0])),  # lons, lats\n",
    "                           sorted(np.unique(site_xys[:, 1])))\n",
    "gridxflat = gridx.ravel()\n",
    "gridyflat = gridy.ravel()\n",
    "\n",
    "# Generate a list of index transfer functions to save and reuse later\n",
    "idxs = np.zeros(nsites, dtype=int)\n",
    "for i in range(nsites):\n",
    "    idxs[i] = np.argwhere((site_xys[i, 0] == gridxflat)\n",
    "                          & (site_xys[i, 1] == gridyflat))[0][0]\n",
    "\n",
    "def fill_mesh(data):\n",
    "    \"\"\"Fills the mesh with the data in the proper locations\"\"\"\n",
    "    output = np.full(gridx.ravel().size, np.nan, dtype=data.dtype)\n",
    "    output[idxs] = data\n",
    "    return output.reshape(gridx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib as mpl\n",
    "from IPython.display import HTML\n",
    "mpl.rc('animation', html='html5')\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "scale = '10m'\n",
    "land = cfeature.NaturalEarthFeature('physical', 'land', scale,\n",
    "                                    edgecolor='face',\n",
    "                                    facecolor=cfeature.COLORS['land'])\n",
    "coast = cfeature.NaturalEarthFeature(category='physical', scale=scale,\n",
    "                                     edgecolor='k',\n",
    "                                     facecolor='none', name='coastline')\n",
    "ocean = cfeature.NaturalEarthFeature(\n",
    "        category='physical',\n",
    "        name='ocean',\n",
    "        scale=scale,\n",
    "        facecolor=cfeature.COLORS['water'])\n",
    "rivers = cfeature.NaturalEarthFeature(\n",
    "        category='physical',\n",
    "        name='rivers_lake_centerlines',\n",
    "        scale=scale,\n",
    "        facecolor=cfeature.COLORS['water'],\n",
    "        edgecolor='face')\n",
    "lakes = cfeature.NaturalEarthFeature(\n",
    "        category='physical',\n",
    "        name='lakes',\n",
    "        scale=scale,\n",
    "        facecolor=cfeature.COLORS['water'],\n",
    "        edgecolor='face')\n",
    "\n",
    "states = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_1_states_provinces_lines',\n",
    "        scale=scale,\n",
    "        facecolor='none',\n",
    "        edgecolor='k')\n",
    "countries = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_0_countries',\n",
    "        scale=scale,\n",
    "        facecolor='none',\n",
    "        edgecolor='k')\n",
    "\n",
    "def get_intersections(df, bbox):\n",
    "    spatial_index = df.sindex\n",
    "\n",
    "    x0, x1, y0, y1 = bbox\n",
    "    polygon = shapely.geometry.Polygon([[x0, y0], [x1, y0], [x1, y1], [x0, y1]])\n",
    "\n",
    "    possible_matches_index = list(spatial_index.intersection(polygon.bounds))\n",
    "    possible_matches = df.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.intersects(polygon)]\n",
    "    return precise_matches\n",
    "\n",
    "def symlog(x):\n",
    "    \"\"\" Returns the symmetric log10 value\"\"\"\n",
    "    # Add one to avoid low values from being shifted lower, we don't\n",
    "    # need exact values here\n",
    "    return np.sign(x) * np.log10(1 + np.abs(x))\n",
    "\n",
    "# line widths go from 0.5 -> 2, equating to 1 -> 1000 km on log scale?\n",
    "line_length_min = 10\n",
    "line_length_max = 1000\n",
    "line_width_min = 0.25\n",
    "line_width_max = 2\n",
    "\n",
    "# Set up the equations\n",
    "def calc_line_width(x, log_scale=False):\n",
    "    if log_scale:\n",
    "        line_width = (np.log10(x) - np.log10(line_length_min))/ \\\n",
    "        (np.log10(line_length_max) - np.log10(line_length_min)) * \\\n",
    "        (line_width_max - line_width_min) + line_width_min\n",
    "    else:\n",
    "        line_width = (x - line_length_min)/ \\\n",
    "        (line_length_max - line_length_min) * \\\n",
    "        (line_width_max - line_width_min) + line_width_min\n",
    "    return np.clip(line_width, a_min=line_width_min, a_max=line_width_max)\n",
    "\n",
    "\n",
    "bbox = (np.min(site_xys[:, 0]), np.max(site_xys[:, 0]),\n",
    "        np.min(site_xys[:, 1]), np.max(site_xys[:, 1]))\n",
    "\n",
    "def setup_axes(ax):\n",
    "    \"\"\"Setup an axes with the proper background, features, and extent.\"\"\"\n",
    "    ax.set_extent(bbox, ccrs.PlateCarree())\n",
    "#     ax.add_feature(coast)\n",
    "    ax.set_facecolor(cfeature.COLORS[\"water\"])\n",
    "    ax.add_feature(cfeature.LAND, color=(0.8, 0.8, 0.8, 1))\n",
    "    ax.add_feature(states, alpha=0.8)\n",
    "    ax.add_feature(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_data = ccrs.PlateCarree()\n",
    "\n",
    "B_norm = mpl.colors.Normalize(0, 1000)\n",
    "B_cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "E_norm = mpl.colors.Normalize(0, 1000)\n",
    "E_cmap = mpl.cm.get_cmap(\"viridis\")\n",
    "\n",
    "I_norm = mpl.colors.Normalize(0, 10)\n",
    "I_cmap = plt.get_cmap(\"plasma\").copy()\n",
    "I_cmap.set_bad(alpha=0.)\n",
    "\n",
    "line_coordinates = [np.array(linestring)[:, :2] for linestring in df['geometry']]\n",
    "line_widths = calc_line_width(df[\"length\"], log_scale=True)\n",
    "\n",
    "\n",
    "def plot_quantity(ax, ds, t=0, quantity=\"B\"):\n",
    "    \"\"\"Plots the requested quantity from the dataset on the axes\"\"\"\n",
    "    if quantity == \"I\":\n",
    "        # We need to add a LineCollection\n",
    "        coll = mpl.collections.LineCollection(line_coordinates)\n",
    "        coll.set_array(np.abs(ds[\"I\"].to_numpy()[t, :]))\n",
    "        coll.set_cmap(I_cmap)\n",
    "        coll.set_norm(I_norm)\n",
    "        coll.set_transform(proj_data)\n",
    "        coll.set_linewidths(line_widths)\n",
    "        ax.add_collection(coll)\n",
    "        return coll\n",
    "\n",
    "    elif quantity == \"B\":\n",
    "        norm = B_norm\n",
    "        cmap = B_cmap\n",
    "    elif quantity == \"E\":\n",
    "        norm = E_norm\n",
    "        cmap = E_cmap\n",
    "\n",
    "    arr = ds[quantity].to_numpy()\n",
    "    arr = np.sqrt(arr[t, :, 0]**2 + arr[t, :, 1]**2)\n",
    "    mesh = ax.pcolormesh(gridx, gridy, fill_mesh(arr),\n",
    "                         transform=proj_data, cmap=cmap, norm=norm, alpha=0.5)\n",
    "    return mesh\n",
    "\n",
    "\n",
    "def update_quantity(coll, ds, t=0, quantity=\"B\"):\n",
    "    if quantity == \"I\":\n",
    "        # Line collection, so just set_array with the new data\n",
    "        coll.set_array(np.abs(ds[quantity].to_numpy()[t, :]))\n",
    "        return\n",
    "    arr = ds[quantity].to_numpy()\n",
    "    arr = np.sqrt(arr[t, :, 0]**2 + arr[t, :, 1]**2)\n",
    "    coll.set_array(fill_mesh(arr).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B + E + TransmissionLine GIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.Mercator()\n",
    "fig, (ax_Bfield, ax_Efield, ax_gic) = plt.subplots(figsize=(8, 12),\n",
    "                                                   nrows=3,\n",
    "                                                   constrained_layout=True,\n",
    "                                                   subplot_kw=dict(projection=projection),\n",
    "                                                   dpi=200)\n",
    "\n",
    "for ax in [ax_Bfield, ax_Efield, ax_gic]:\n",
    "    setup_axes(ax)\n",
    "\n",
    "t = 0\n",
    "ds = mage_ds\n",
    "model_name = \"MAGE\"\n",
    "times = ds[\"time\"].dt.strftime('%Y/%m/%d %H:%M').to_numpy()\n",
    "title = ax_Bfield.set_title(f\"{model_name}\\n{times[t]}\")\n",
    "\n",
    "B_mesh = plot_quantity(ax_Bfield, ds, t=t, quantity=\"B\")\n",
    "E_mesh = plot_quantity(ax_Efield, ds, t=t, quantity=\"E\")\n",
    "I_coll = plot_quantity(ax_gic, ds, t=t, quantity=\"I\")\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Bfield, mappable=B_mesh, orientation='vertical')\n",
    "cbar.set_label('Magnetic Field ($nT$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Efield, mappable=E_mesh, orientation='vertical')\n",
    "cbar.set_label('Electric Field ($mV/km$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax, mappable=I_coll, orientation='vertical')\n",
    "cbar.set_label('GIC Proxy ($A$)')\n",
    "\n",
    "fig.canvas.draw()\n",
    "fig.canvas.draw()\n",
    "fig.set_constrained_layout(False)\n",
    "\n",
    "def animate(t):\n",
    "    title.set_text(f\"{model_name}\\n{times[t]}\")\n",
    "    update_quantity(B_mesh, ds, t=t, quantity=\"B\")\n",
    "    update_quantity(E_mesh, ds, t=t, quantity=\"E\")\n",
    "    update_quantity(I_coll, ds, t=t, quantity=\"I\")\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, animate, frames=range(len(times)))\n",
    "anim.save(f\"{model_name}-Halloween.mp4\", dpi=200)\n",
    "plt.close()\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.Mercator()\n",
    "fig, (ax_Bfield, ax_Efield, ax_gic) = plt.subplots(figsize=(8, 12),\n",
    "                                                   nrows=3,\n",
    "                                                   constrained_layout=True,\n",
    "                                                   subplot_kw=dict(projection=projection),\n",
    "                                                   dpi=200)\n",
    "\n",
    "for ax in [ax_Bfield, ax_Efield, ax_gic]:\n",
    "    setup_axes(ax)\n",
    "\n",
    "t = 0\n",
    "ds = swpc_ds\n",
    "model_name = \"SWPC\"\n",
    "times = ds[\"time\"].dt.strftime('%Y/%m/%d %H:%M').to_numpy()\n",
    "title = ax_Bfield.set_title(f\"{model_name}\\n{times[t]}\")\n",
    "\n",
    "B_mesh = plot_quantity(ax_Bfield, ds, t=t, quantity=\"B\")\n",
    "E_mesh = plot_quantity(ax_Efield, ds, t=t, quantity=\"E\")\n",
    "I_coll = plot_quantity(ax_gic, ds, t=t, quantity=\"I\")\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Bfield, mappable=B_mesh, orientation='vertical')\n",
    "cbar.set_label('Magnetic Field ($nT$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Efield, mappable=E_mesh, orientation='vertical')\n",
    "cbar.set_label('Electric Field ($mV/km$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax, mappable=I_coll, orientation='vertical')\n",
    "cbar.set_label('GIC Proxy ($A$)')\n",
    "\n",
    "fig.canvas.draw()\n",
    "fig.canvas.draw()\n",
    "fig.set_constrained_layout(False)\n",
    "\n",
    "def animate(t):\n",
    "    title.set_text(f\"{model_name}\\n{times[t]}\")\n",
    "    update_quantity(B_mesh, ds, t=t, quantity=\"B\")\n",
    "    update_quantity(E_mesh, ds, t=t, quantity=\"E\")\n",
    "    update_quantity(I_coll, ds, t=t, quantity=\"I\")\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, animate, frames=range(len(times)))\n",
    "anim.save(f\"{model_name}-Halloween.mp4\", dpi=200)\n",
    "plt.close()\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.Mercator()\n",
    "fig, (ax_Bfield, ax_Efield, ax_gic) = plt.subplots(figsize=(8, 12),\n",
    "                                                   nrows=3,\n",
    "                                                   constrained_layout=True,\n",
    "                                                   subplot_kw=dict(projection=projection),\n",
    "                                                   dpi=200)\n",
    "\n",
    "for ax in [ax_Bfield, ax_Efield, ax_gic]:\n",
    "    setup_axes(ax)\n",
    "\n",
    "t = 0\n",
    "ds = umich_ds\n",
    "model_name = \"UMICH\"\n",
    "times = ds[\"time\"].dt.strftime('%Y/%m/%d %H:%M').to_numpy()\n",
    "title = ax_Bfield.set_title(f\"{model_name}\\n{times[t]}\")\n",
    "\n",
    "B_mesh = plot_quantity(ax_Bfield, ds, t=t, quantity=\"B\")\n",
    "E_mesh = plot_quantity(ax_Efield, ds, t=t, quantity=\"E\")\n",
    "I_coll = plot_quantity(ax_gic, ds, t=t, quantity=\"I\")\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Bfield, mappable=B_mesh, orientation='vertical')\n",
    "cbar.set_label('Magnetic Field ($nT$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Efield, mappable=E_mesh, orientation='vertical')\n",
    "cbar.set_label('Electric Field ($mV/km$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax, mappable=I_coll, orientation='vertical')\n",
    "cbar.set_label('GIC Proxy ($A$)')\n",
    "\n",
    "fig.canvas.draw()\n",
    "fig.canvas.draw()\n",
    "fig.set_constrained_layout(False)\n",
    "\n",
    "def animate(t):\n",
    "    title.set_text(f\"{model_name}\\n{times[t]}\")\n",
    "    update_quantity(B_mesh, ds, t=t, quantity=\"B\")\n",
    "    update_quantity(E_mesh, ds, t=t, quantity=\"E\")\n",
    "    update_quantity(I_coll, ds, t=t, quantity=\"I\")\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, animate, frames=range(len(times)))\n",
    "anim.save(f\"{model_name}-Halloween.mp4\", dpi=200)\n",
    "plt.close()\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.Mercator()\n",
    "fig, (ax_Bfield, ax_Efield, ax_gic) = plt.subplots(figsize=(8, 12),\n",
    "                                                   nrows=3,\n",
    "                                                   constrained_layout=True,\n",
    "                                                   subplot_kw=dict(projection=projection),\n",
    "                                                   dpi=200)\n",
    "\n",
    "for ax in [ax_Bfield, ax_Efield, ax_gic]:\n",
    "    setup_axes(ax)\n",
    "\n",
    "t = 0\n",
    "ds = mage_ds\n",
    "model_name = \"MAGE\"\n",
    "times = ds[\"time\"].dt.strftime('%Y/%m/%d %H:%M').to_numpy()\n",
    "title = ax_Bfield.set_title(f\"{model_name}\\n{times[t]}\")\n",
    "\n",
    "B_mesh = plot_quantity(ax_Bfield, ds, t=t, quantity=\"B\")\n",
    "E_mesh = plot_quantity(ax_Efield, ds, t=t, quantity=\"E\")\n",
    "I_coll = plot_quantity(ax_gic, ds, t=t, quantity=\"I\")\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Bfield, mappable=B_mesh, orientation='vertical')\n",
    "cbar.set_label('Magnetic Field ($nT$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax_Efield, mappable=E_mesh, orientation='vertical')\n",
    "cbar.set_label('Electric Field ($mV/km$)')\n",
    "\n",
    "cbar = fig.colorbar(ax=ax, mappable=I_coll, orientation='vertical')\n",
    "cbar.set_label('GIC Proxy ($A$)')\n",
    "\n",
    "fig.canvas.draw()\n",
    "fig.canvas.draw()\n",
    "fig.set_constrained_layout(False)\n",
    "\n",
    "def animate(t):\n",
    "    title.set_text(f\"{model_name}\\n{times[t]}\")\n",
    "    update_quantity(B_mesh, ds, t=t, quantity=\"B\")\n",
    "    update_quantity(E_mesh, ds, t=t, quantity=\"E\")\n",
    "    update_quantity(I_coll, ds, t=t, quantity=\"I\")\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, animate, frames=range(len(times)))\n",
    "anim.save(f\"{model_name}-Halloween.mp4\", dpi=200)\n",
    "plt.close()\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
